BERT Results:
100	0.9963	0.9656	0.4653	0.4655	0.4896	0.5648	0.4320	0.8814	0.8157
Counter({1.0: 571, 2.0: 65, 3.0: 24, 6.0: 7, 5.0: 7, 4.0: 5, 11.0: 3, 9.0: 3, 18.0: 2, 33.0: 2, 8.0: 2, 10.0: 1, 30.0: 1, 16.0: 1, 13.0: 1, 23.0: 1, 25.0: 1, 12.0: 1, 7.0: 1, 24.0: 1})
[[392400    271]
 [  1179    587]]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    392671
           1       0.68      0.33      0.45      1766

    accuracy                           1.00    394437
   macro avg       0.84      0.67      0.72    394437
weighted avg       1.00      1.00      1.00    394437




Decomposable Attention + Elmo Softmax Results:
100	0.9964	0.9451	0.4395	0.4396	0.4599	0.5991	0.3732	0.8239	0.7443
Counter({1.0: 521, 2.0: 68, 3.0: 34, 5.0: 13, 4.0: 11, 6.0: 10, 7.0: 7, 8.0: 4, 9.0: 4, 12.0: 4, 13.0: 3, 10.0: 2, 91.0: 2, 17.0: 2, 139.0: 1, 50.0: 1, 18.0: 1, 26.0: 1, 332.0: 1, 19.0: 1, 52.0: 1, 11.0: 1, 23.0: 1, 228.0: 1, 25.0: 1, 27.0: 1, 73.0: 1, 105.0: 1, 15.0: 1})
[[392492    179]
 [  1245    521]]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    392671
           1       0.74      0.30      0.42      1766

    accuracy                           1.00    394437
   macro avg       0.87      0.65      0.71    394437
weighted avg       1.00      1.00      1.00    394437




Ensemble Results:
100	0.9966	0.9663	0.5634	0.5635	0.5476	0.6037	0.5011	0.8795	0.8114
Counter({1.0: 568, 2.0: 72, 3.0: 14, 4.0: 10, 6.0: 9, 7.0: 6, 5.0: 5, 10.0: 4, 18.0: 2, 17.0: 2, 38.0: 1, 33.0: 1, 24.0: 1, 12.0: 1, 8.0: 1, 9.0: 1, 58.0: 1, 14.0: 1})
[[392539    132]
 [  1198    568]]
              precision    recall  f1-score   support

           0       1.00      1.00      1.00    392671
           1       0.81      0.32      0.46      1766

    accuracy                           1.00    394437
   macro avg       0.90      0.66      0.73    394437
weighted avg       1.00      1.00      1.00    394437


